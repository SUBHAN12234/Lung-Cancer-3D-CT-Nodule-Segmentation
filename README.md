# Lung-Cancer-3D-CT-Nodule-Segmentation
3D Lung Nodule Segmentation using 3D U-NetOverviewThis project focuses on developing a deep learning model for the accurate segmentation of lung nodules from 3D Computed Tomography (CT) scans. Early and precise detection of lung nodules is crucial for the timely diagnosis of lung cancer, significantly improving patient outcomes. This repository provides the code, trained models, and documentation for a 3D U-Net architecture implemented using TensorFlow and Keras.Problem StatementLung cancer remains one of the leading causes of cancer-related deaths worldwide. CT scans are widely used for screening and diagnosis, but manually identifying and delineating small lung nodules is a time-consuming and error-prone task for radiologists. Automated segmentation methods can significantly assist in this process by providing consistent and rapid analysis, thereby enhancing diagnostic accuracy and efficiency.Model Architecture: 3D U-NetThe core of this project is a 3D U-Net, a convolutional neural network architecture renowned for its effectiveness in biomedical image segmentation. The 3D U-Net extends the original 2D U-Net by processing volumetric data directly, allowing it to capture spatial context across slices, which is vital for 3D medical images like CT scans.The architecture consists of:Encoder (Contracting Path): Downsamples the input CT volume through a series of 3D convolutional layers and max-pooling operations, extracting hierarchical features.Decoder (Expansive Path): Upsamples the feature maps, combining them with high-resolution features from the encoder via skip connections. These skip connections are crucial for propagating fine-grained spatial information, enabling precise localization of nodules.Output Layer: A final 3D convolutional layer with a sigmoid activation function outputs a probability map, indicating the likelihood of each voxel belonging to a lung nodule.DatasetThis project utilizes a subset of the Lung Image Database Consortium (LIDC-IDRI) dataset. The LIDC-IDRI dataset is a publicly available resource containing thoracic CT scans with marked-up annotated lesions by multiple radiologists. The data undergoes preprocessing steps to ensure consistency and suitability for 3D deep learning models.Key Technologies UsedPython: The primary programming language.TensorFlow & Keras: Deep learning framework for building, training, and evaluating the 3D U-Net model.NumPy: For numerical operations and data handling.WSL2 (Windows Subsystem for Linux 2) & NVIDIA GPU: For accelerated training and inference.Git & GitHub: For version control and project hosting.PerformanceThe model was trained for a total of 28 epochs (initially 20, then resumed for 8 more until EarlyStopping triggered). The best performing model, identified at Epoch 23, demonstrated strong generalization capabilities on the unseen test set.Here are the final evaluation metrics on the test dataset for the best overall model (Epoch 23):Loss (Dice Loss): 0.3260Accuracy: 0.9992Mean IoU (Intersection over Union): 0.6768Dice Coefficient: 0.6740These results indicate a robust performance in segmenting lung nodules, achieving a high degree of overlap with the ground truth annotations.Project StructureThe repository is organized as follows:Lung-Cancer-3D-CT-Nodule-Segmentation/
├── data/
│   ├── processed/          # Preprocessed CT scans and masks (e.g., .npy files)
│   └── splits/             # Files defining train, validation, and test splits
├── models/
│   ├── best_overall_3d_unet_model.keras  # The absolute best model saved across all runs (Epoch 23)
│   ├── final_3d_unet_model.keras         # Best model from the last training session (also Epoch 23)
│   └── final_3d_unet_model_epoch_20_best.keras # (Your manual backup of Epoch 20)
├── checkpoints/             # Saved model checkpoints from each epoch during training
│   ├── model_epoch_01.keras
│   ├── ...
│   └── model_epoch_28.keras
├── evaluation_results/     # Directory to store test evaluation results
│   └── test_results_YYYYMMDD_HHMMSS.txt
├── src/
│   ├── data_loader.py      # Script for loading and preprocessing data
│   ├── model.py            # Defines the 3D U-Net model architecture
│   ├── train.py            # Script for training the model
│   └── evaluate_model.py   # Script for evaluating the trained model on test data
├── .gitignore              # Specifies files/directories to ignore in Git (e.g., checkpoints/)
└── README.md               # This file
Setup and InstallationClone the Repository:git clone https://github.com/SUBHAN12234/Lung-Cancer-3D-CT-Nodule-Segmentation.git
cd Lung-Cancer-3D-CT-Nodule-Segmentation
Set up Conda Environment (Recommended for GPU support):Ensure you have Miniconda or Anaconda installed.conda create -n tf-gpu python=3.9
conda activate tf-gpu
pip install tensorflow[and-cuda]==2.15.0 # Or your specific TF/CUDA version
pip install numpy pandas scikit-learn matplotlib
Note: Adjust tensorflow[and-cuda]==2.15.0 based on your CUDA/cuDNN setup if necessary.Prepare Data:Obtain the LIDC-IDRI dataset.Run your data preprocessing script (if you have one, or manually place processed .npy files into data/processed and split definitions into data/splits as per your data_loader.py).UsageTraining the ModelTo start or resume training the 3D U-Net model:Configure src/train.py:Adjust TOTAL_TARGET_EPOCHS as desired.Set RESUME_TRAINING = True and LAST_CHECKPOINT_PATH to the .keras file of the epoch you wish to resume from (e.g., ./checkpoints/model_epoch_20.keras).Run Training:conda activate tf-gpu
cd src/
python train.py
The training process will save epoch checkpoints in checkpoints/ and the best model from the run (based on val_loss) to models/final_3d_unet_model.keras. The models/best_overall_3d_unet_model.keras will also be updated if a new all-time best val_loss is achieved.Evaluating the ModelTo evaluate the best trained model on the unseen test dataset:Configure src/evaluate_model.py:Ensure MODEL_TO_EVALUATE_PATH points to the model you want to test (e.g., models/best_overall_3d_unet_model.keras).Run Evaluation:conda activate tf-gpu
cd src/
python evaluate_model.py
The results will be printed to the console and saved to a timestamped text file in the evaluation_results/ directory.Future WorkAdvanced Data Augmentation: Implement more sophisticated 3D data augmentation techniques (e.g., elastic deformations, intensity shifts) to improve model robustness.Hyperparameter Optimization: Conduct a more thorough search for optimal learning rates, batch sizes, and network configurations.Loss Function Exploration: Experiment with hybrid loss functions (e.g., Dice + BCE) or focal loss to address class imbalance more effectively.Model Ensembling: Combine predictions from multiple trained models to potentially achieve higher overall performance.Post-processing: Implement post-processing techniques on the segmentation masks (e.g., connected component analysis, morphological operations) to refine predictions.Quantification & Visualization: Develop tools for quantitative analysis of nodule characteristics and 3D visualization of segmentation results.AcknowledgementsLIDC-IDRI Dataset: This project utilizes data from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) public database.TensorFlow & Keras Teams: For providing powerful and flexible deep learning frameworks.